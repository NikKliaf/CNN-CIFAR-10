{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YyzDpfXYoZtN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functions\n",
    "import torch.optim as optimize\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZiT87Fg0qW49"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uj8wvAeOqymN",
    "outputId": "3131119c-686b-4fad-ba54-f61c6785f052"
   },
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root = \"./dataset\", train = True, transform= transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root = \"./dataset\", train = False, transform= transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Kci3O8VKrImP",
    "outputId": "de91d811-f193-41eb-df49-4b95b8b9792f"
   },
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jOfbQziKrXTA"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    def conv_block(in_channels, out_channels, pool=False):\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if pool:\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    self.layer1 = conv_block(3,64)     \n",
    "    self.layer2 = conv_block(64, 64, pool=True)\n",
    "\n",
    "    self.layer3 = conv_block(64, 128)\n",
    "    self.layer4 = conv_block(128, 128, pool=True)\n",
    "\n",
    "    self.layer5 = conv_block(128, 256)\n",
    "    self.layer6 = conv_block(256, 256, pool=True)\n",
    "\n",
    "    self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc = nn.Linear(256,10)\n",
    "\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "      \n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "      \n",
    "    x = self.layer5(x)\n",
    "    x = self.layer6(x)\n",
    "\n",
    "    x = self.gap(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7QsHvAe4u_94"
   },
   "outputs": [],
   "source": [
    "network = NeuralNetwork().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optimize.SGD(network.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "5TuTdoRDvKkV",
    "outputId": "2f88044b-da3c-45b4-f32f-eee91024acfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training...\n",
      "Epoch: 1/20 | Train loss: 1.513 | Train Accuracy: 44.890% | Time: 224.463 sec|\n",
      "Epoch: 2/20 | Train loss: 1.018 | Train Accuracy: 63.652% | Time: 229.091 sec|\n",
      "Epoch: 3/20 | Train loss: 0.812 | Train Accuracy: 71.318% | Time: 222.894 sec|\n",
      "Epoch: 4/20 | Train loss: 0.674 | Train Accuracy: 76.608% | Time: 228.952 sec|\n",
      "Epoch: 5/20 | Train loss: 0.579 | Train Accuracy: 79.830% | Time: 231.453 sec|\n",
      "Epoch: 6/20 | Train loss: 0.504 | Train Accuracy: 82.626% | Time: 225.305 sec|\n",
      "Epoch: 7/20 | Train loss: 0.442 | Train Accuracy: 84.924% | Time: 232.351 sec|\n",
      "Epoch: 8/20 | Train loss: 0.388 | Train Accuracy: 86.680% | Time: 231.368 sec|\n",
      "Epoch: 9/20 | Train loss: 0.348 | Train Accuracy: 87.958% | Time: 223.167 sec|\n",
      "Epoch: 10/20 | Train loss: 0.306 | Train Accuracy: 89.480% | Time: 228.034 sec|\n",
      "Epoch: 11/20 | Train loss: 0.278 | Train Accuracy: 90.470% | Time: 224.229 sec|\n",
      "Epoch: 12/20 | Train loss: 0.245 | Train Accuracy: 91.528% | Time: 225.244 sec|\n",
      "Epoch: 13/20 | Train loss: 0.228 | Train Accuracy: 92.106% | Time: 232.971 sec|\n",
      "Epoch: 14/20 | Train loss: 0.200 | Train Accuracy: 92.940% | Time: 220.440 sec|\n",
      "Epoch: 15/20 | Train loss: 0.183 | Train Accuracy: 93.674% | Time: 226.148 sec|\n",
      "Epoch: 16/20 | Train loss: 0.165 | Train Accuracy: 94.320% | Time: 230.090 sec|\n",
      "Epoch: 17/20 | Train loss: 0.158 | Train Accuracy: 94.432% | Time: 223.578 sec|\n",
      "Epoch: 18/20 | Train loss: 0.142 | Train Accuracy: 95.054% | Time: 228.742 sec|\n",
      "Epoch: 19/20 | Train loss: 0.131 | Train Accuracy: 95.488% | Time: 228.822 sec|\n",
      "Epoch: 20/20 | Train loss: 0.126 | Train Accuracy: 95.608% | Time: 222.086 sec|\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "print(\"Started training...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    network.train() \n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = network(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader)\n",
    "        epoch_train_acc = 100 * correct_train / total_train\n",
    "    \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs} | \"\n",
    "          f\"Train loss: {epoch_train_loss:.3f} | \"\n",
    "          f\"Train Accuracy: {epoch_train_acc:.3f}% | \"\n",
    "          f\"Time: {epoch_duration:.3f} sec|\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N34bDjbCwJM9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(network.state_dict(), \"./model.pth\")\n",
    "network = NeuralNetwork()\n",
    "network.load_state_dict(torch.load(\"./model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zC8ExBxxwhF6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.540%\n",
      "Loss: 0.635%\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "                                                  \n",
    "    outputs = network(images)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    test_loss += loss\n",
    "      \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_test_acc = 100 * correct / total\n",
    "final_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Accuracy: {final_test_acc:.3f}%\")\n",
    "print(f\"Loss: {final_test_loss:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NNDL(venv)",
   "language": "python",
   "name": "nndl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
